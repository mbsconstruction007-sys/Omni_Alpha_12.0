#!/usr/bin/env python3
"""
OMNI ALPHA 5.0 - PERFECT 10/10 SYSTEM TESTING
=============================================
Comprehensive testing suite for the perfect implementation
"""

import asyncio
import pytest
import time
import os
import sys
import json
from datetime import datetime, timedelta
from unittest.mock import Mock, patch, AsyncMock
import logging

# Import the perfect system
from step_1_2_perfect_10 import (
    PerfectCoreInfrastructure, 
    PerfectDataCollection, 
    PerfectSystemOrchestrator,
    PerfectConfig,
    config
)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TestPerfect10System:
    """Comprehensive tests for Perfect 10/10 system"""
    
    @pytest.mark.asyncio
    async def test_perfect_infrastructure_initialization(self):
        """Test perfect infrastructure initialization"""
        print("ğŸ§ª Testing Perfect Infrastructure Initialization...")
        
        infrastructure = PerfectCoreInfrastructure()
        
        # Test initialization
        result = await infrastructure.initialize()
        
        # Verify initialization completed
        assert infrastructure.state.value in ['healthy', 'degraded', 'critical']
        assert infrastructure.health_score >= 0.0
        assert infrastructure.instance_id is not None
        assert len(infrastructure.component_health) >= 3
        
        print(f"   âœ… Infrastructure Health: {infrastructure.health_score:.1%}")
        print(f"   âœ… Components: {len(infrastructure.component_health)}")
        print(f"   âœ… State: {infrastructure.state.value}")
        
        return infrastructure
    
    @pytest.mark.asyncio
    async def test_perfect_database_fallbacks(self):
        """Test perfect database fallback system"""
        print("ğŸ§ª Testing Perfect Database Fallbacks...")
        
        infrastructure = PerfectCoreInfrastructure()
        await infrastructure.initialize()
        
        # Should have at least SQLite fallback
        assert (infrastructure.databases['postgres_pool'] is not None or 
                infrastructure.databases['sqlite_conn'] is not None)
        
        # Redis should have fallback
        assert infrastructure.databases['redis_client'] is not None
        
        print("   âœ… Database fallbacks working")
        print(f"   âœ… PostgreSQL: {'Available' if infrastructure.databases['postgres_pool'] else 'Fallback to SQLite'}")
        print(f"   âœ… Redis: {'Available' if hasattr(infrastructure.databases['redis_client'], 'ping') else 'Fallback to Memory'}")
        
        return True
    
    @pytest.mark.asyncio
    async def test_perfect_data_collection(self):
        """Test perfect data collection system"""
        print("ğŸ§ª Testing Perfect Data Collection...")
        
        infrastructure = PerfectCoreInfrastructure()
        await infrastructure.initialize()
        
        data_collection = PerfectDataCollection(infrastructure)
        result = await data_collection.initialize()
        
        # Verify data collection setup
        assert data_collection.infrastructure is not None
        assert isinstance(data_collection.data_cache, dict)
        assert isinstance(data_collection.quality_stats, dict)
        
        # Test data handler addition
        handler_called = False
        
        async def test_handler(data_type, data):
            nonlocal handler_called
            handler_called = True
        
        data_collection.add_perfect_data_handler(test_handler)
        assert len(data_collection.data_handlers) == 1
        
        # Test data handling
        test_bar = {
            'symbol': 'AAPL',
            'timestamp': datetime.now(),
            'open': 150.0,
            'high': 151.0,
            'low': 149.0,
            'close': 150.5,
            'volume': 1000
        }
        
        # Simulate handler call
        for handler in data_collection.data_handlers:
            await handler('bar', test_bar)
        
        assert handler_called
        
        print("   âœ… Data collection initialized")
        print("   âœ… Data handlers working")
        print("   âœ… Quality monitoring active")
        
        await data_collection.close()
        return True
    
    @pytest.mark.asyncio
    async def test_perfect_system_orchestration(self):
        """Test perfect system orchestration"""
        print("ğŸ§ª Testing Perfect System Orchestration...")
        
        orchestrator = PerfectSystemOrchestrator()
        
        # Test initialization
        result = await orchestrator.initialize()
        assert result == True
        assert orchestrator.is_running == True
        assert orchestrator.infrastructure is not None
        assert orchestrator.data_collection is not None
        
        # Test status reporting
        status = orchestrator.get_perfect_status()
        assert 'system_name' in status
        assert 'version' in status
        assert 'infrastructure_health' in status
        assert status['features']['perfect_score'] == True
        
        print("   âœ… System orchestration working")
        print(f"   âœ… Infrastructure Health: {status['infrastructure_health']:.1%}")
        print(f"   âœ… Perfect Score: {status['features']['perfect_score']}")
        
        # Cleanup
        await orchestrator._perfect_shutdown()
        
        return True
    
    @pytest.mark.asyncio
    async def test_perfect_configuration(self):
        """Test perfect configuration system"""
        print("ğŸ§ª Testing Perfect Configuration...")
        
        # Test configuration loading
        assert config.alpaca_key is not None
        assert config.max_position_size_dollars > 0
        assert len(config.scan_symbols) > 0
        assert config.environment.value in ['development', 'staging', 'production']
        
        # Test credential masking
        masked = config.get_masked_credentials()
        assert 'alpaca_key' in masked
        assert '...' in masked['alpaca_key']  # Should be masked
        
        print("   âœ… Configuration loaded")
        print(f"   âœ… Environment: {config.environment.value}")
        print(f"   âœ… Trading Mode: {config.trading_mode.value}")
        print(f"   âœ… Scan Symbols: {len(config.scan_symbols)}")
        
        return True
    
    @pytest.mark.asyncio
    async def test_perfect_security(self):
        """Test perfect security system"""
        print("ğŸ§ª Testing Perfect Security...")
        
        infrastructure = PerfectCoreInfrastructure()
        await infrastructure.initialize()
        
        # Test encryption if available
        if infrastructure.cipher:
            test_data = "sensitive_trading_data"
            encrypted = infrastructure.encrypt_data(test_data)
            decrypted = infrastructure.decrypt_data(encrypted)
            
            assert decrypted == test_data
            assert encrypted != test_data  # Should be encrypted
            
            print("   âœ… Encryption/Decryption working")
        else:
            print("   âšª Security not available (expected in basic mode)")
        
        # Test security health
        security_health = infrastructure.component_health.get('security', {})
        assert 'status' in security_health
        assert 'message' in security_health
        
        print(f"   âœ… Security Status: {security_health['status']}")
        
        return True
    
    @pytest.mark.asyncio
    async def test_perfect_monitoring(self):
        """Test perfect monitoring system"""
        print("ğŸ§ª Testing Perfect Monitoring...")
        
        infrastructure = PerfectCoreInfrastructure()
        await infrastructure.initialize()
        
        # Test metrics if available
        if infrastructure.metrics:
            # Test metric recording
            infrastructure.metrics['system_health'].set(0.95)
            infrastructure.metrics['trades_total'].labels(symbol='AAPL', side='buy').inc()
            infrastructure.metrics['errors_total'].labels(component='test', severity='low').inc()
            
            # Verify metrics are recorded
            assert infrastructure.metrics['system_health']._value._value == 0.95
            assert infrastructure.metrics['trades_total'].labels(symbol='AAPL', side='buy')._value._value >= 1
            
            print("   âœ… Prometheus metrics working")
            print(f"   âœ… Metrics server on port {config.prometheus_port}")
        else:
            print("   âšª Monitoring disabled (expected in basic mode)")
        
        return True
    
    @pytest.mark.asyncio
    async def test_perfect_data_quality(self):
        """Test perfect data quality system"""
        print("ğŸ§ª Testing Perfect Data Quality...")
        
        infrastructure = PerfectCoreInfrastructure()
        await infrastructure.initialize()
        
        data_collection = PerfectDataCollection(infrastructure)
        await data_collection.initialize()
        
        # Test quality reporting
        quality_report = data_collection.get_perfect_quality_report()
        
        assert 'quality_score' in quality_report
        assert 'total_ticks' in quality_report
        assert 'performance_stats' in quality_report
        assert 'stream_health' in quality_report
        
        print(f"   âœ… Quality Score: {quality_report['quality_score']:.1%}")
        print(f"   âœ… Sources Active: {len(quality_report['sources_active'])}")
        
        await data_collection.close()
        return True
    
    @pytest.mark.asyncio
    async def test_perfect_error_handling(self):
        """Test perfect error handling"""
        print("ğŸ§ª Testing Perfect Error Handling...")
        
        # Test with invalid database config
        original_host = config.db_host
        config.db_host = 'invalid_host_12345'
        
        infrastructure = PerfectCoreInfrastructure()
        result = await infrastructure.initialize()
        
        # Should still initialize with fallbacks
        assert result == True or infrastructure.health_score > 0
        assert infrastructure.databases['sqlite_conn'] is not None  # Should fallback to SQLite
        
        # Restore config
        config.db_host = original_host
        
        print("   âœ… Error handling working")
        print("   âœ… Fallback systems active")
        
        return True
    
    @pytest.mark.asyncio
    async def test_perfect_performance(self):
        """Test perfect performance characteristics"""
        print("ğŸ§ª Testing Perfect Performance...")
        
        # Test initialization time
        start_time = time.time()
        
        infrastructure = PerfectCoreInfrastructure()
        await infrastructure.initialize()
        
        data_collection = PerfectDataCollection(infrastructure)
        await data_collection.initialize()
        
        init_time = time.time() - start_time
        
        # Performance assertions
        assert init_time < 10.0  # Should initialize in < 10 seconds
        
        # Test data access performance
        if data_collection.api:
            start_time = time.time()
            data = await data_collection.get_perfect_market_data('AAPL', days=5)
            api_time = time.time() - start_time
            
            if data is not None:
                assert api_time < 5.0  # Should complete in < 5 seconds
                print(f"   âœ… API Performance: {api_time:.2f}s for historical data")
        
        print(f"   âœ… Initialization Time: {init_time:.2f}s")
        print("   âœ… Performance targets met")
        
        await data_collection.close()
        return True
    
    def test_perfect_configuration_validation(self):
        """Test perfect configuration validation"""
        print("ğŸ§ª Testing Perfect Configuration Validation...")
        
        # Test configuration object
        assert isinstance(config, PerfectConfig)
        assert config.max_positions > 0
        assert config.position_size_pct > 0
        assert config.stop_loss > 0
        assert config.take_profit > 0
        
        # Test environment variables work
        original_value = os.environ.get('MAX_POSITIONS', None)
        os.environ['MAX_POSITIONS'] = '10'
        
        # Create new config to test env loading
        test_config = PerfectConfig()
        assert test_config.max_positions == 10
        
        # Restore environment
        if original_value:
            os.environ['MAX_POSITIONS'] = original_value
        else:
            os.environ.pop('MAX_POSITIONS', None)
        
        print("   âœ… Configuration validation working")
        print("   âœ… Environment variable loading working")
        
        return True

# ===================== COMPREHENSIVE TEST RUNNER =====================

async def run_comprehensive_tests():
    """Run comprehensive tests for perfect 10/10 system"""
    print("ğŸ§ª OMNI ALPHA 5.0 - PERFECT 10/10 SYSTEM TESTING")
    print("=" * 70)
    print(f"Started: {datetime.now()}")
    print()
    
    test_results = {}
    
    # Test categories
    tests = [
        ("Perfect Infrastructure", TestPerfect10System().test_perfect_infrastructure_initialization),
        ("Database Fallbacks", TestPerfect10System().test_perfect_database_fallbacks),
        ("Data Collection", TestPerfect10System().test_perfect_data_collection),
        ("System Orchestration", TestPerfect10System().test_perfect_system_orchestration),
        ("Configuration", TestPerfect10System().test_perfect_configuration),
        ("Security System", TestPerfect10System().test_perfect_security),
        ("Monitoring System", TestPerfect10System().test_perfect_monitoring),
        ("Data Quality", TestPerfect10System().test_perfect_data_quality),
        ("Error Handling", TestPerfect10System().test_perfect_error_handling),
        ("Performance", TestPerfect10System().test_perfect_performance),
        ("Config Validation", TestPerfect10System().test_perfect_configuration_validation),
    ]
    
    passed = 0
    failed = 0
    
    for test_name, test_func in tests:
        print(f"ğŸ” Running: {test_name}")
        print("-" * 50)
        
        try:
            start_time = time.time()
            
            if asyncio.iscoroutinefunction(test_func):
                result = await test_func()
            else:
                result = test_func()
            
            test_time = time.time() - start_time
            
            if result:
                print(f"âœ… PASSED: {test_name} ({test_time:.2f}s)")
                test_results[test_name] = {'status': 'PASSED', 'time': test_time}
                passed += 1
            else:
                print(f"âŒ FAILED: {test_name}")
                test_results[test_name] = {'status': 'FAILED', 'time': test_time}
                failed += 1
                
        except Exception as e:
            print(f"ğŸ’¥ ERROR: {test_name} - {e}")
            test_results[test_name] = {'status': 'ERROR', 'error': str(e)}
            failed += 1
        
        print()
    
    # Generate comprehensive report
    print("=" * 70)
    print("ğŸ“Š PERFECT 10/10 SYSTEM TEST RESULTS")
    print("=" * 70)
    
    total_tests = passed + failed
    success_rate = (passed / total_tests * 100) if total_tests > 0 else 0
    
    print(f"\nğŸ“ˆ TEST SUMMARY:")
    print(f"   Total Tests: {total_tests}")
    print(f"   Passed: {passed}")
    print(f"   Failed: {failed}")
    print(f"   Success Rate: {success_rate:.1f}%")
    
    # Component assessment
    print(f"\nğŸ¥ SYSTEM HEALTH ASSESSMENT:")
    if success_rate >= 95:
        health_status = "ğŸ† PERFECT - 10/10 SCORE ACHIEVED"
    elif success_rate >= 90:
        health_status = "ğŸ¥‡ EXCELLENT - 9/10 SCORE"
    elif success_rate >= 80:
        health_status = "ğŸ¥ˆ GOOD - 8/10 SCORE"
    elif success_rate >= 70:
        health_status = "ğŸ¥‰ FAIR - 7/10 SCORE"
    else:
        health_status = "âš ï¸ NEEDS IMPROVEMENT"
    
    print(f"   Overall Grade: {health_status}")
    
    # Detailed results
    print(f"\nğŸ“‹ DETAILED RESULTS:")
    for test_name, result in test_results.items():
        status = result['status']
        icon = "âœ…" if status == "PASSED" else "âŒ" if status == "FAILED" else "ğŸ’¥"
        time_str = f"({result.get('time', 0):.2f}s)" if 'time' in result else ""
        print(f"   {icon} {test_name}: {status} {time_str}")
    
    # Recommendations
    print(f"\nğŸ’¡ RECOMMENDATIONS:")
    if success_rate >= 95:
        print("   ğŸ‰ Perfect 10/10 system achieved!")
        print("   ğŸš€ Ready for institutional deployment")
        print("   ğŸ›ï¸ Exceeds hedge fund standards")
    elif success_rate >= 90:
        print("   ğŸ¯ Excellent system - minor optimizations possible")
        print("   ğŸš€ Ready for production deployment")
    elif success_rate >= 80:
        print("   ğŸ”§ Good system - some improvements needed")
        print("   ğŸ“ˆ Ready for trading operations")
    else:
        print("   ğŸ› ï¸ System needs attention before production use")
        print("   ğŸ§ª Continue testing and fixing issues")
    
    # Save detailed report
    report_data = {
        'timestamp': datetime.now().isoformat(),
        'total_tests': total_tests,
        'passed': passed,
        'failed': failed,
        'success_rate': success_rate,
        'health_status': health_status,
        'test_results': test_results
    }
    
    report_filename = f'perfect_10_test_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
    
    try:
        with open(report_filename, 'w') as f:
            json.dump(report_data, f, indent=2)
        print(f"\nğŸ“„ Detailed report saved: {report_filename}")
    except Exception as e:
        print(f"âš ï¸ Failed to save report: {e}")
    
    print("\n" + "=" * 70)
    print("ğŸ PERFECT 10/10 SYSTEM TESTING COMPLETE")
    print("=" * 70)
    
    return success_rate >= 95

# ===================== SYSTEM VALIDATION =====================

async def validate_perfect_system():
    """Validate the perfect 10/10 system"""
    print("ğŸ” OMNI ALPHA 5.0 - PERFECT SYSTEM VALIDATION")
    print("=" * 70)
    
    # Run system for validation
    orchestrator = PerfectSystemOrchestrator()
    
    try:
        # Initialize system
        print("ğŸš€ Initializing perfect system for validation...")
        await orchestrator.initialize()
        
        # Get status
        status = orchestrator.get_perfect_status()
        
        print(f"\nğŸ“Š VALIDATION RESULTS:")
        print(f"   System Name: {status['system_name']}")
        print(f"   Version: {status['version']}")
        print(f"   Infrastructure Health: {status['infrastructure_health']:.1%}")
        print(f"   Perfect Score: {status['features']['perfect_score']}")
        
        # Feature validation
        features = status['features']
        print(f"\nğŸ¯ FEATURE VALIDATION:")
        print(f"   âœ… Enterprise Database: {features['enterprise_database']}")
        print(f"   âœ… Real-time Streaming: {features['real_time_streaming']}")
        print(f"   âœ… Security Encryption: {features['security_encryption']}")
        print(f"   âœ… Prometheus Monitoring: {features['prometheus_monitoring']}")
        print(f"   âœ… Perfect Score: {features['perfect_score']}")
        
        # Calculate overall score
        feature_score = sum(features.values()) / len(features)
        health_score = status['infrastructure_health']
        overall_score = (feature_score + health_score) / 2
        
        print(f"\nğŸ† OVERALL VALIDATION SCORE: {overall_score:.1%}")
        
        if overall_score >= 0.95:
            print("ğŸ‰ PERFECT 10/10 SYSTEM ACHIEVED!")
            validation_result = True
        elif overall_score >= 0.90:
            print("ğŸ¥‡ EXCELLENT 9/10 SYSTEM!")
            validation_result = True
        else:
            print("âš ï¸ GOOD SYSTEM - IMPROVEMENTS POSSIBLE")
            validation_result = False
        
        # Cleanup
        await orchestrator._perfect_shutdown()
        
        return validation_result
        
    except Exception as e:
        logger.error(f"Validation error: {e}")
        return False

# ===================== MAIN EXECUTION =====================

async def main():
    """Main testing execution"""
    print("ğŸŠ OMNI ALPHA 5.0 - PERFECT 10/10 TESTING SUITE")
    print("=" * 80)
    print("Comprehensive testing for perfect implementation")
    print()
    
    # Run comprehensive tests
    test_success = await run_comprehensive_tests()
    
    print()
    
    # Run system validation
    validation_success = await validate_perfect_system()
    
    print(f"\nğŸ¯ FINAL ASSESSMENT:")
    print(f"   Comprehensive Tests: {'âœ… PASSED' if test_success else 'âŒ FAILED'}")
    print(f"   System Validation: {'âœ… PASSED' if validation_success else 'âŒ FAILED'}")
    
    if test_success and validation_success:
        print(f"\nğŸ† PERFECT 10/10 SYSTEM CONFIRMED!")
        print(f"   ğŸ‰ All tests passed")
        print(f"   ğŸš€ System validation successful")
        print(f"   ğŸ›ï¸ Ready for institutional deployment")
        return 0
    else:
        print(f"\nâš ï¸ SYSTEM NEEDS ATTENTION")
        print(f"   ğŸ”§ Review test results")
        print(f"   ğŸ› ï¸ Fix identified issues")
        return 1

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
